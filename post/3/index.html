<!DOCTYPE html>
<html>
  <head>
    
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-173578745-1"></script>
    <script>
      if (window.location.host==="charx7.me" || window.location.host === "www.charx7.me") {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-173578745-1');
      }
    </script>

    
      <title>Carlos Portfolio - Static website using python, flask, and frozen-flask (1)</title>
    
    <!-- Bootstrap -->
    <link rel="stylesheet" type="text/css" 
      href="/static//css/bootstrap.css">
    <link rel="stylesheet" type="text/css"
      href="/static//css/main.css">  
      <!-- Font Awsome CDN -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
    
    <link rel="stylesheet" type="text/css"
      href="/static//css/colorful.css">
    
  </head>

  <!-- Pigments for code CSS -->
  

  <body>
    <header class="site-header"></header>

    <nav class="navbar navbar-expand-md navbar-dark bg-steel fixed-top">
      <div class="container">
        <a class="navbar-brand mr-4" href="/">Carlos Huerta</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarToggle" aria-controls="navbarToggle" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarToggle">
          <div class="navbar-nav mr-auto">
            <a class="nav-item nav-link" href="/about.html">About</a>
            <a class="nav-item nav-link" href="/index.html">Blog</a>
            <a class="nav-item nav-link" href="/portfolio.html">Portfolio</a>
          </div>
          <!-- Navbar Right Side 
          <div class="navbar-nav">
            <a class="nav-item nav-link" href="/login">Login</a>
            <a class="nav-item nav-link" href="/register">Register</a>
          </div>
          -->
        </div>
      </div>
    </nav>

    <!-- Paralax Image-->
    <div class = "parallax">
      <!-- Paralax Text-->
      <div class = "container-title-text">
        <h1 id="parallax-title">Carlos Huerta - Data Science Blog</h1>
      </div>
    </div>
    
    <!-- Main content-->
    <div class="main-content">
      <div class="container">
        
  <div class="content-section">
    <h2>Association rule mining using the parallel fp-growth algorithm using spark, docker and mongodb (2)</h2>
    <p>By Carlos Huerta on Aug 06 2020</p>
    <div><h3>How to build a scalable recommendation engine ‚öôÔ∏è</h3>
<p>This is a continuation of <a  target="_blank" href="https://charx7.me/post/2/">part 1</a> of the series on how to build a scalable recommendation engine.</p>
<h2>2. Create and submit a job to the docker spark-cluster</h2>
<p>By the end of part 1 we still needed to develop and submit our spark job to our cluster, so inside the <code>jobs</code> directory create a file named <code>FpJob.py</code>. At first, we are going to be using the built-in spark-ml library. In the next part, we will develop the algorithm to gain insight into how our recommendations are being built.</p>
<h3>2.1 Spark job set-up</h3>
<p>Inside our mongo container, we stored our data inside a <strong>transactions</strong> database and a <strong>transactions</strong> collection. In our case the read pyspark data-frame object will be:  </p>
<div class="codehilite"><pre><span></span><code>+--------------------+-------------+--------------------+
<span class="p">|</span>         ProductCode<span class="p">|</span>TransactionID<span class="p">|</span>                 _id<span class="p">|</span>
+--------------------+-------------+--------------------+
<span class="p">|</span>             <span class="o">[</span><span class="m">44848</span><span class="o">]</span><span class="p">|</span>         <span class="m">3932</span><span class="p">|</span><span class="o">[</span>5c965c83d771ffb4...<span class="p">|</span>
<span class="p">|</span>      <span class="o">[</span><span class="m">40694</span>, <span class="m">44848</span><span class="o">]</span><span class="p">|</span>         <span class="m">3935</span><span class="p">|</span><span class="o">[</span>5c965c83d771ffb4...<span class="p">|</span>
<span class="p">|</span>             <span class="o">[</span><span class="m">28306</span><span class="o">]</span><span class="p">|</span>         <span class="m">3936</span><span class="p">|</span><span class="o">[</span>5c965c83d771ffb4...<span class="p">|</span>
<span class="p">|</span>             <span class="o">[</span><span class="m">44976</span><span class="o">]</span><span class="p">|</span>         <span class="m">3938</span><span class="p">|</span><span class="o">[</span>5c965c83d771ffb4...<span class="p">|</span>
<span class="p">|</span>             <span class="o">[</span><span class="m">43409</span><span class="o">]</span><span class="p">|</span>         <span class="m">3941</span><span class="p">|</span><span class="o">[</span>5c965c83d771ffb4...<span class="p">|</span>
<span class="p">|</span>             <span class="o">[</span><span class="m">21442</span><span class="o">]</span><span class="p">|</span>         <span class="m">3943</span><span class="p">|</span><span class="o">[</span>5c965c83d771ffb4...<span class="p">|</span>
<span class="p">|</span>      <span class="o">[</span><span class="m">25065</span>, <span class="m">32817</span><span class="o">]</span><span class="p">|</span>         <span class="m">3944</span><span class="p">|</span><span class="o">[</span>5c965c83d771ffb4...<span class="p">|</span>
<span class="p">|</span>             <span class="o">[</span><span class="m">30706</span><span class="o">]</span><span class="p">|</span>         <span class="m">3945</span><span class="p">|</span><span class="o">[</span>5c965c83d771ffb4...<span class="p">|</span>
<span class="p">|</span><span class="o">[</span><span class="m">21442</span>, <span class="m">26749</span>, <span class="m">32</span>...<span class="p">|</span>         <span class="m">3946</span><span class="p">|</span><span class="o">[</span>5c965c83d771ffb4...<span class="p">|</span>
<span class="p">|</span>      <span class="o">[</span><span class="m">21414</span>, <span class="m">43330</span><span class="o">]</span><span class="p">|</span>         <span class="m">3950</span><span class="p">|</span><span class="o">[</span>5c965c83d771ffb4...<span class="p">|</span>
<span class="p">|</span>             <span class="o">[</span><span class="m">15572</span><span class="o">]</span><span class="p">|</span>         <span class="m">3952</span><span class="p">|</span><span class="o">[</span>5c965c83d771ffb4...<span class="p">|</span>
<span class="p">|</span>             <span class="o">[</span><span class="m">41206</span><span class="o">]</span><span class="p">|</span>         <span class="m">3954</span><span class="p">|</span><span class="o">[</span>5c965c83d771ffb4...<span class="p">|</span>
<span class="p">|</span><span class="o">[</span><span class="m">35059</span>, <span class="m">40664</span>, <span class="m">40</span>...<span class="p">|</span>         <span class="m">3955</span><span class="p">|</span><span class="o">[</span>5c965c83d771ffb4...<span class="p">|</span>
<span class="p">|</span>      <span class="o">[</span><span class="m">21138</span>, <span class="m">33208</span><span class="o">]</span><span class="p">|</span>         <span class="m">3957</span><span class="p">|</span><span class="o">[</span>5c965c83d771ffb4...<span class="p">|</span>
<span class="p">|</span>             <span class="o">[</span><span class="m">24756</span><span class="o">]</span><span class="p">|</span>         <span class="m">3959</span><span class="p">|</span><span class="o">[</span>5c965c83d771ffb4...<span class="p">|</span>
<span class="p">|</span>             <span class="o">[</span><span class="m">13958</span><span class="o">]</span><span class="p">|</span>         <span class="m">3961</span><span class="p">|</span><span class="o">[</span>5c965c83d771ffb4...<span class="p">|</span>
<span class="p">|</span>      <span class="o">[</span><span class="m">28010</span>, <span class="m">41206</span><span class="o">]</span><span class="p">|</span>         <span class="m">3962</span><span class="p">|</span><span class="o">[</span>5c965c83d771ffb4...<span class="p">|</span>
<span class="p">|</span><span class="o">[</span><span class="m">20702</span>, <span class="m">21901</span>, <span class="m">22</span>...<span class="p">|</span>         <span class="m">3963</span><span class="p">|</span><span class="o">[</span>5c965c83d771ffb4...<span class="p">|</span>
<span class="p">|</span>             <span class="o">[</span><span class="m">23642</span><span class="o">]</span><span class="p">|</span>         <span class="m">3964</span><span class="p">|</span><span class="o">[</span>5c965c83d771ffb4...<span class="p">|</span>
<span class="p">|</span><span class="o">[</span><span class="m">23370</span>, <span class="m">26825</span>, <span class="m">32</span>...<span class="p">|</span>         <span class="m">3967</span><span class="p">|</span><span class="o">[</span>5c965c83d771ffb4...<span class="p">|</span>
+--------------------+-------------+--------------------+
</code></pre></div>


<p>The column <code>ProductCode</code> contains all the product codes from bought items of a given transaction. The <code>TransactionID</code> column is the id of a given transaction, and <code>_id</code> is the internal mongodb id given on insert. We have both ids since our transactions do not natively live inside our mongo-db, but we could have only fetched them from our native db instead of building a mongo-db to store our data. This design is up to you üòÄ and your company's needs.</p>
<div class="input">
  MY_PROJECT_NAME/pyspark_src/pyspark_recom_engine/jobs/Fp_job.py
</div>

<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.fpm</span> <span class="kn">import</span> <span class="n">FPGrowth</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># Read from the transactions database and transactions collection, this will</span>
    <span class="c1"># generate a Dataframe object</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reading from transactions db... </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">transactions_data</span> <span class="o">=</span> <span class="n">spark_session</span><span class="o">.</span><span class="n">read</span> \
        <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;com.mongodb.spark.sql.DefaultSource&quot;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;database&quot;</span><span class="p">,</span> <span class="s2">&quot;transactions&quot;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;collection&quot;</span><span class="p">,</span> <span class="s2">&quot;transactions&quot;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">load</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Our read transactions are of the type: &#39;</span><span class="p">,</span><span class="nb">type</span><span class="p">(</span><span class="n">transactions_data</span><span class="p">),</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The generated transactions schema is: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">transactions_data</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The data fetched from the dbb is: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">transactions_data</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="n">product_codes</span> <span class="o">=</span> <span class="n">transactions_data</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;ProductCode&quot;</span><span class="p">)</span>
    <span class="n">fpGrowth</span> <span class="o">=</span> <span class="n">FPGrowth</span><span class="p">(</span><span class="n">itemsCol</span><span class="o">=</span><span class="s2">&quot;ProductCode&quot;</span><span class="p">,</span>
                        <span class="n">minSupport</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">minConfidence</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Fitting the model...&#39;</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">fpGrowth</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">product_codes</span><span class="p">)</span>

    <span class="c1"># Display frequent itemsets.</span>
    <span class="n">model</span><span class="o">.</span><span class="n">freqItemsets</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1"># Display generated association rules.</span>
    <span class="n">model</span><span class="o">.</span><span class="n">associationRules</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>

    <span class="c1"># transform examines the input items against all the association rules and summarize the</span>
    <span class="c1"># consequents as prediction</span>
    <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">transactions_data</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1"># Simple test stuff to write to the db</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Writing to the mongodb&quot;</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">associationRules</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="s2">&quot;com.mongodb.spark.sql.DefaultSource&quot;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;database&quot;</span><span class="p">,</span> <span class="s2">&quot;transactions&quot;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;collection&quot;</span><span class="p">,</span> <span class="s2">&quot;recommendations&quot;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="s2">&quot;append&quot;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="c1"># There is a bug that doesnt pass spark session objects when called from another func</span>
    <span class="n">spark_session</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span> \
        <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;recomEngine&quot;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.mongodb.input.uri&quot;</span><span class="p">,</span> <span class="s2">&quot;mongodb://spark-mongo:27017/testdb.myColl&quot;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.mongodb.output.uri&quot;</span><span class="p">,</span> <span class="s2">&quot;mongodb://spark-mongo:27017/testdb.myColl&quot;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s1">&#39;spark.jars.packages&#39;</span><span class="p">,</span> <span class="s2">&quot;org.mongodb.spark:mongo-spark-connector_2.11:2.4.0&quot;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
    <span class="n">spark_session</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">.</span><span class="n">setLogLevel</span><span class="p">(</span><span class="s2">&quot;ERROR&quot;</span><span class="p">)</span>  <span class="c1"># Set log level to error</span>
    <span class="c1"># Execute main method</span>
    <span class="n">main</span><span class="p">()</span>
</code></pre></div>


<p>We used mongo-db to read and write both our transactions and recommendations data, although we could have used any other database or read directly from a file; the advantage of doing it this way is that we can replace both the input and output database URLs <code>mongodb://spark-mongo:27017/testdb.myColl</code> to the URL where your data is stored.</p>
<h3>2.2 Spark job submit and execution.</h3>
<p>To submit the job to our spark cluster, we need to create another container; this container will communicate to the spark master and execute the job provided. We also need to build our python package to import all of our inner dependencies without any problems. To build and run both our docker image and our python package, we will use the automation tool <code>make</code>, which requires a <code>makefile</code> that defines a set of tasks to be executed. </p>
<p>Create a <code>makefile</code> on the root of the project:</p>
<div class="input">
  MY_PROJECT_NAME/makefile
</div>

<div class="codehilite"><pre><span></span><code><span class="nf">help</span><span class="o">:</span>
    @echo <span class="s2">&quot;submit-app    - Will submit the python prebuilt app into the cluster&quot;</span>
    @echo <span class="s2">&quot;package-pyspark-app: - Will package a python egg to submit into spark&quot;</span>

<span class="nf">package-pyspark-app</span><span class="o">:</span>
    @echo <span class="s2">&quot;Packaging the python egg to be submitted alongside the job...&quot;</span>
    @<span class="o">(</span><span class="nb">cd</span> ./pyspark_src <span class="o">&amp;&amp;</span> python setup.py bdist_egg<span class="o">)</span>

<span class="nf">submit-app</span><span class="o">:</span>
    @echo <span class="s2">&quot;Package python app -&gt; Built Docker Image -&gt; Run the Submit container&quot;</span>
    make package-pyspark-app
    @echo <span class="s2">&quot;Submiting app into the cluster&quot;</span>
    @docker build --rm -t submit-pyspark-job ./pyspark_src/
    @echo <span class="s2">&quot;Image built, now running the submit container&quot;</span> 
    @docker run --rm --name pyspark-app -e <span class="nv">ENABLE_INIT_DAEMON</span><span class="o">=</span><span class="nb">false</span> -p <span class="m">4040</span>:4040 --network spark-network submit-pyspark-job
    @echo <span class="s2">&quot;Removing hanging images...&quot;</span>
    @docker rmi <span class="k">$(</span>shell docker images -f <span class="s2">&quot;dangling=true&quot;</span> -q<span class="k">)</span>
</code></pre></div>


<ul>
<li>The <code>help</code> command is just a reminder of the tasks we have defined.</li>
<li>The <code>package-pyspark-app</code> command runs the <code>setup.py</code> script, so our package, which contains our pyspark job gets build and then gets deployed into the submit container.</li>
<li>The <code>submit-app</code> command builds the docker image, runs, and connects it via the <code>spark-network</code> to the (previously) created spark-cluster.</li>
</ul>
<p>Note: In order for the <code>package-pyspark-app</code> command to properly work, we need to have activated our virtual-environment, which contains the pyspark and other dependencies required to build the python package.</p>
<h3>2.4 Model Results</h3>
<p>The output dataframe of the mined association rules will look something like this:</p>
<div class="codehilite"><pre><span></span><code>+--------------------+----------+--------------------+------------------+
<span class="p">|</span>          antecedent<span class="p">|</span>consequent<span class="p">|</span>          confidence<span class="p">|</span>              lift<span class="p">|</span>
+--------------------+----------+--------------------+------------------+
<span class="p">|</span>             <span class="o">[</span><span class="m">26758</span><span class="o">]</span><span class="p">|</span>   <span class="o">[</span><span class="m">26772</span><span class="o">]</span><span class="p">|</span> <span class="m">0</span>.19786096256684493<span class="p">|</span><span class="m">113</span>.28364527629235<span class="p">|</span>
<span class="p">|</span>             <span class="o">[</span><span class="m">44287</span><span class="o">]</span><span class="p">|</span>   <span class="o">[</span><span class="m">39297</span><span class="o">]</span><span class="p">|</span>              <span class="m">0</span>.1125<span class="p">|</span>         <span class="m">154</span>.58625<span class="p">|</span>
<span class="p">|</span>             <span class="o">[</span><span class="m">44287</span><span class="o">]</span><span class="p">|</span>   <span class="o">[</span><span class="m">39299</span><span class="o">]</span><span class="p">|</span>           <span class="m">0</span>.1296875<span class="p">|</span><span class="m">180</span>.36800986842107<span class="p">|</span>
...
+--------------------+----------+--------------------+------------------+
</code></pre></div>


<p>Which contains the product code of the <strong>antecedent</strong>, the recommendation or <strong>consequent</strong> product code, and two qualitative metrics, <strong>confidence</strong> and <strong>lift</strong> which tell us how <em>sure</em> we are on our recommendation. In this case, our most confident rule was: if you bought a screwdriver, the model recommends you buy a different type of screwdriver, which is pretty logical. 
Finally, this table is saved into the mongo database and can then be used as a lookup table to check for recommendations on our e-commerce website. </p>
<h3>2.5 To put it in a nutshell</h3>
<p>Once we have all the architecture set-up it is not that hard to create and submit different spark jobs, to summarize: to submit the ml-lib fp-growth pyspark job we have to do the following:
* Initialize the spark cluster via <code>docker-compose</code> using the <code>docker-compose up</code> command.
* In the root of our project using the make tool run the <code>make submit-app</code> which will build our custom pyspark job and submit it using a custom docker submit image.</p>
<p>In the third part, we are going to take a look into the insights of the <strong>parallel fp-growth</strong> algorithm and implement it ourselves from scratch using only spark core functions.</p></div>
    
    <br>
    <!-- Needed for disqus-->
    <div id="disqus_thread"></div>

  </div>

        
        <!-- Footer -->
        <div class="border-top pt-3">
          <small class="text-muted">
              Made with ‚ù§Ô∏è using flask, frozen-flask, Bootstrap
          </small>

          <div class="right-footer">
            <a href="https://github.com/charx7" style="color: black!important; text-decoration: none;">
              <i class="fa fa-github" style="padding-right: 16px"></i>
            </a>
    
            <a href="https://www.linkedin.com/in/carlos-rodolfo-huerta-santiago-2b5609100/" style="color: black!important; text-decoration: none">
              <i class="fa fa-linkedin" style="padding-right: 16px"></i>
            </a>
          </div>
          
        </div>
      </div>
    </div>
    
    <!-- jQuery -->
    <script
			  src="https://code.jquery.com/jquery-3.5.1.min.js"
			  integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
        crossorigin="anonymous"></script>
    <!--  BS js -->
    <script type="text/javascript"
      src="/static/js/bootstrap.bundle.js"></script>

    

<script>
  var disqus_config = function () {
  this.page.url = 'https://charx7.me/post/3/';  // Your page's canonical URL variable
  this.page.identifier = '3'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
  };
  (function() { // DON'T EDIT BELOW THIS LINE
  var d = document, s = d.createElement('script');
  s.src = 'https://carlos-huerta-blog.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
                          


  </body>
</html>